{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib widget\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import typing as t\n",
        "\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "import numpy\n",
        "from numpy.typing import NDArray, ArrayLike"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "Steps in MLs reconstruction:\n",
        "\n",
        " - Setup\n",
        "   - Make incident probe(s)\n",
        "   - Generate scan positions\n",
        "   - Generate object, large enough to contain $[1/d, 1/d]$ region around every scan position\n",
        "   - Load and process measured patterns\n",
        " - Running\n",
        "  - Pre-Calculate probe intensity (sum of probe intensity in object space)\n",
        "    - High illumination -> good est. of object wavefunction\n",
        "  - Pre-Calculate object intensity (sum of object intensity in probe space)\n",
        "    - High object magnitude -> good signal of probe wavefunction\n",
        "    - important for opaque regions/obstructions\n",
        "\n",
        "  - Per iteration\n",
        "    - Split probe positions into groupings\n",
        "\n",
        "    - Per grouping\n",
        "      - Add to probe & object intensity\n",
        "\n",
        "      - Apply forward model to detector plane\n",
        "      - Apply modulus constraint at detector plane\n",
        "      - Calculate exit wavefunction update chi\n",
        "      - Calculate object and probe update directions, per probe position\n",
        "      - Average object and probe update directions\n",
        "      - Calculate probe and object update step size, per probe position\n",
        "      - Apply probe and object update weighted by object and probe intensity\n",
        "\n",
        "    - Update probe & object intensity\n",
        "\n",
        "## Conventions\n",
        "\n",
        "- Reciprocal space: Zero-frequency in corner\n",
        "- Real space: (0, 0) in center\n",
        "- Energy is normalized in both reciprocal space:\n",
        "  - $ \\sum \\left|f(x, y)\\right|^2 = 1 $\n",
        "  - $ \\sum \\left|F(k_x, k_y)\\right|^2 = N_x N_y $\n",
        "- Probe and object is stored in real space\n",
        "\n",
        "## Implications\n",
        "\n",
        "- FFTs need 'forward' normalization\n",
        "- Reciprocal space to real space: `f = fftshift(ifft2(F, norm='forward'), axes=(-2, -1))`\n",
        "- Real space to reciprocal space: `F = fft2(ifftshift(f, axes=(-2, -1)), norm='forward')`\n",
        "- Normalize energy in real space: `abs2(f) / numpy.prod(f.shape[-2:])`\n",
        "- Normalize amplitude in real space: `f / numpy.sqrt(numpy.prod(f.shape[-2:]))`\n",
        "- Never need to fftshift in reciprocal space"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ptycho_lebeau.raw import load_4d\n",
        "from ptycho_lebeau.metadata import AnyMetadata\n",
        "import eutils\n",
        "\n",
        "meta = AnyMetadata.parse_file(\"/Users/colin/Downloads/mos2/1/mos2/mos2_0.00_dstep1.0.json\")\n",
        "print(meta.json(indent='    '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw = load_4d(meta.path / meta.raw_filename)\n",
        "# fftshift patterns to corners\n",
        "raw = numpy.fft.fftshift(raw, axes=(-1, -2)).reshape((-1, *raw.shape[-2:]))\n",
        "# normalize patterns\n",
        "raw /= numpy.sum(raw, axis=(-2, -1))[:, None, None]\n",
        "\n",
        "dose = 100000  # e/A^2\n",
        "px_area = numpy.prod(numpy.array(meta.scan_step) * 1e10)\n",
        "dose_per_pattern = dose * px_area\n",
        "# e * 1.602e-19 C/e / 1e-3 s * 1e12 pA/A -> pA\n",
        "print(f\"Equiv. beam current: {(dose_per_pattern * 1.6021766e-07) / 1e-3:.3f} pA\")\n",
        "\n",
        "# apply poisson noise\n",
        "noisy = numpy.random.poisson(dose_per_pattern * raw).astype(numpy.float32) / dose_per_pattern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Various helper functions"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.linalg import lstsq\n",
        "\n",
        "def ifft2(a: ArrayLike) -> NDArray[numpy.complex_]:\n",
        "    return numpy.fft.fftshift(numpy.fft.ifft2(a, norm='forward'), axes=(-2, -1))\n",
        "\n",
        "def fft2(a: ArrayLike) -> NDArray[numpy.complex_]:\n",
        "    return numpy.fft.fft2(numpy.fft.ifftshift(a, axes=(-2, -1)), norm='forward')\n",
        "\n",
        "def fourier_shift_filter(ky: numpy.ndarray, kx: numpy.ndarray, shifts: ArrayLike) -> NDArray[numpy.complex_]:\n",
        "    shifts = numpy.array(shifts)\n",
        "    if shifts.ndim == 1:\n",
        "        (x, y) = shifts\n",
        "        return numpy.exp(-2.j*numpy.pi*(x*kx + y*ky))\n",
        "\n",
        "    out = numpy.empty((*shifts.shape[:-1], *ky.shape), dtype=numpy.complex_)\n",
        "    for idxs in numpy.ndindex(shifts.shape[:-1]):\n",
        "        (x, y) = shifts[*idxs]\n",
        "        out[*idxs] = numpy.exp(-2.j*numpy.pi*(x*kx + y*ky))\n",
        "\n",
        "    return out\n",
        "\n",
        "def remove_phase_ramp(data: numpy.ndarray) -> numpy.ndarray:\n",
        "    output = numpy.empty_like(data)\n",
        "\n",
        "    (yy, xx) = (arr.flatten() for arr in numpy.indices(data.shape[-2:], dtype=float))\n",
        "    pts = numpy.stack((numpy.ones_like(xx), xx, yy), axis=-1)\n",
        "\n",
        "    for idx in numpy.ndindex(data.shape[:-2]):\n",
        "        layer = data[*idx]\n",
        "        p, residues, rank, singular = lstsq(pts, layer.flatten())\n",
        "        output[*idx] = layer - (p @ pts.T).reshape(layer.shape)\n",
        "\n",
        "    return output\n",
        "\n",
        "def calc_groupings(grouping: int = 8, seed: t.Any = None) -> list[NDArray[numpy.int_]]:\n",
        "    rng = numpy.random.RandomState(seed)\n",
        "    idxs = numpy.arange(raw.shape[0])\n",
        "    rng.shuffle(idxs)\n",
        "    return numpy.array_split(idxs, numpy.ceil(raw.shape[0] / grouping).astype(numpy.int_))\n",
        "\n",
        "def abs2(x: NDArray[numpy.complexfloating]) -> NDArray[numpy.floating]:\n",
        "    return x.real**2. + x.imag**2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make probe & propagators"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "wavelength = eutils.Electron(meta.voltage / 1e3).wavelength\n",
        "\n",
        "kstep = meta.diff_step*1e-3 / wavelength\n",
        "(b, a) = (1/kstep,) * 2\n",
        "\n",
        "(px_size_y, px_size_x) = (b/raw.shape[-2], a/raw.shape[-1])\n",
        "\n",
        "yy = numpy.linspace(-b/2, b/2, raw.shape[-2], endpoint=False)\n",
        "xx = numpy.linspace(-a/2, a/2, raw.shape[-1], endpoint=False)\n",
        "yy, xx = numpy.meshgrid(yy, xx, indexing='ij')\n",
        "\n",
        "# TODO switch with something more elegant\n",
        "ky = numpy.fft.fftfreq(raw.shape[-2], b/raw.shape[-2])\n",
        "kx = numpy.fft.fftfreq(raw.shape[-1], a/raw.shape[-1])\n",
        "ky, kx = numpy.meshgrid(ky, kx, indexing='ij')\n",
        "\n",
        "thetay, thetax = ky * wavelength, kx * wavelength\n",
        "theta2 = thetay**2 + thetax**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO check sign of defocus\n",
        "\n",
        "chi = meta.defocus * 1e10 * (theta2 / 2)\n",
        "init_probe = numpy.exp(chi * -2.j*numpy.pi / wavelength)\n",
        "# mask reciprocal space to aperture\n",
        "aperture_mask = theta2 <= (meta.conv_angle * 1e-3)**2\n",
        "init_probe *= aperture_mask\n",
        "# normalize amplitude\n",
        "init_probe /= numpy.sqrt(numpy.sum(numpy.abs(init_probe)))\n",
        "\n",
        "init_probe = ifft2(init_probe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = pyplot.subplots(ncols=2)\n",
        "\n",
        "ax1.imshow(abs2(init_probe))\n",
        "ax2.imshow(numpy.fft.fftshift(abs2(fft2(init_probe))))\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probe modes"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_hermetian_modes(base_probe: numpy.ndarray, n_modes: int, powers: ArrayLike = 0.02):\n",
        "    powers = numpy.array(powers, dtype=numpy.float64).ravel()\n",
        "    powers = numpy.pad(powers, (0, n_modes - len(powers) - 1), mode='edge')[:n_modes - 1]\n",
        "    base_power = 1. - numpy.sum(powers)\n",
        "    powers = numpy.concatenate(([base_power], powers))\n",
        "\n",
        "    n_y = numpy.ceil(numpy.sqrt(n_modes)).astype(numpy.int_)\n",
        "    n_x = numpy.ceil(n_modes / (n_y + 1)).astype(numpy.int_)\n",
        "\n",
        "    print(f\"{n_y=}, {n_x=}\")\n",
        "\n",
        "    realspace_norm = numpy.sqrt(numpy.prod(base_probe.shape[-2:]))\n",
        "    modes = hermetian_modes(base_probe, n_y, n_x)[:n_modes] * numpy.sqrt(powers)[:, None, None] * realspace_norm\n",
        "\n",
        "    return modes\n",
        "\n",
        "def hermetian_modes(base_probe: numpy.ndarray, n_y: int, n_x: int) -> numpy.ndarray:\n",
        "    (yy, xx) = numpy.indices(base_probe.shape, dtype=numpy.float64)\n",
        "\n",
        "    base_probe_mag = abs2(base_probe)\n",
        "\n",
        "    (com_y, com_x) = (numpy.sum(a * base_probe_mag) / numpy.sum(base_probe_mag) for a in (yy, xx))\n",
        "    yy -= com_y\n",
        "    xx -= com_x\n",
        "    (var_y, var_x) = (numpy.sum(a**2. * base_probe_mag) / numpy.sum(base_probe_mag) for a in (yy, xx))\n",
        "\n",
        "    modes = []\n",
        "\n",
        "    for i in range(n_y):\n",
        "        for j in range(n_x):\n",
        "            mode = yy**i * xx**j * base_probe\n",
        "            if i > 1 or j > 1:\n",
        "                mode = mode * numpy.exp(-xx**2./(2 * var_x) - yy*2./(2 * var_y))\n",
        "                mode /= numpy.sqrt(numpy.sum(abs2(mode)))\n",
        "\n",
        "            # orthogonalize to other modes\n",
        "            for prev_mode in modes:\n",
        "                mode -= prev_mode * numpy.sum(prev_mode * numpy.conj(mode))\n",
        "\n",
        "            mode /= numpy.sqrt(numpy.sum(abs2(mode)))\n",
        "            modes.append(mode)\n",
        "\n",
        "    return numpy.stack(modes, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_probes = 4\n",
        "\n",
        "modes = make_hermetian_modes(init_probe, n_probes)\n",
        "\n",
        "fig, axs = pyplot.subplots(ncols=n_probes, sharex=True, sharey=True)\n",
        "\n",
        "for (ax, mode) in zip(axs.flat, modes):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(abs2(mode))\n",
        "    print(numpy.sum(abs2(fft2(mode))))\n",
        "\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# debug mode correlations and intensities, should be orthogonal\n",
        "\n",
        "init_probes = make_hermetian_modes(init_probe, 4)\n",
        "\n",
        "img = numpy.zeros((len(init_probes),) * 2)\n",
        "\n",
        "energy_norm = numpy.prod(init_probe.shape[-2:])\n",
        "\n",
        "for i in range(len(init_probes)):\n",
        "    for j in range(len(init_probes)):\n",
        "        img[i,j] = numpy.abs(numpy.sum(init_probes[i] * numpy.conj(init_probes[j]))) / energy_norm\n",
        "\n",
        "fig, ax = pyplot.subplots()\n",
        "ax.imshow(img)\n",
        "\n",
        "#for (ax, mode) in zip(axs.flat, modes):\n",
        "#    ax.set_axis_off()\n",
        "#    ax.imshow(numpy.abs(mode)**2.)\n",
        "\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make scan"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "scanx = (numpy.arange(meta.scan_shape[0], dtype=numpy.float_) - meta.scan_shape[0] / 2.) * meta.scan_step[0] * 1e10\n",
        "scany = (numpy.arange(meta.scan_shape[1], dtype=numpy.float_) - meta.scan_shape[1] / 2.) * meta.scan_step[1] * 1e10\n",
        "scany, scanx = map(numpy.ravel, numpy.meshgrid(scany, scanx, indexing='ij'))\n",
        "# shape (n, 2)\n",
        "scan = numpy.stack((scanx, scany), axis=-1)\n",
        "\n",
        "fig, ax = pyplot.subplots()\n",
        "ax.invert_yaxis()\n",
        "ax.set_aspect(1.)\n",
        "ax.scatter(scan[:, 0], scan[:, 1], s=1.)\n",
        "ax.scatter([scan[2, 0]], [scan[2, 1]], c='red', s=2.)\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make object"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_min, x_max = numpy.nanmin(scanx), numpy.nanmax(scanx)\n",
        "y_min, y_max = numpy.nanmin(scany), numpy.nanmax(scany)\n",
        "\n",
        "# pad for outer positions\n",
        "sim_r = numpy.max((a, b)) / 2. + numpy.max((px_size_x, px_size_y)) * 2.\n",
        "x_min -= sim_r\n",
        "y_min -= sim_r\n",
        "x_max += sim_r\n",
        "y_max += sim_r\n",
        "\n",
        "# TODO check this for off-by-one\n",
        "\n",
        "# keep x_min and x_max, calculate number of object pixels required\n",
        "n_x = numpy.ceil((x_max - x_min) / px_size_x).astype(numpy.int_) + 1\n",
        "n_y = numpy.ceil((y_max - y_min) / px_size_x).astype(numpy.int_) + 1\n",
        "\n",
        "# update x_max and y_max\n",
        "x_max = x_min + n_x * px_size_x\n",
        "y_max = y_min + n_y * px_size_y\n",
        "\n",
        "fig, ax = pyplot.subplots()\n",
        "ax.set_aspect(1.)\n",
        "ax.add_patch(patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, fill=False, transform=ax.transData))\n",
        "i, j = (a[0] for a in numpy.split(numpy.indices((n_y, n_x)), 2, axis=0))\n",
        "xx = x_min + j * px_size_x\n",
        "yy = y_min + i * px_size_y\n",
        "ax.pcolormesh(x_min + j * px_size_x, y_min + i*px_size_y, i)\n",
        "ax.scatter(scanx, scany, s=1, c='red')\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "slice_around_position(*group_scan[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# handle object cutouts and subpixel probe shifting\n",
        "\n",
        "def pos_to_object_idx(pos: ArrayLike) -> NDArray[numpy.float_]:\n",
        "    return (numpy.array(pos) - numpy.array([x_min, y_min])) / [px_size_x, px_size_y] - numpy.array(ky.shape[-2:]) / 2.\n",
        "\n",
        "def slice_around_position(x: float, y: float) -> t.Tuple[slice, slice]:\n",
        "    (start_j, start_i) = numpy.round(pos_to_object_idx((x, y))).astype(numpy.int_)\n",
        "    #start_i = numpy.round((y - y_min) / px_size_y - ky.shape[-2] / 2).astype(numpy.int_)\n",
        "    #start_j = numpy.round((x - x_min) / px_size_x - ky.shape[-1] / 2).astype(numpy.int_)\n",
        "    return (\n",
        "        slice(start_i, start_i + ky.shape[-2]),\n",
        "        slice(start_j, start_j + ky.shape[-1]),\n",
        "    )\n",
        "\n",
        "def get_subpx_shifts(pos: ArrayLike) -> NDArray[numpy.float_]:\n",
        "    pos = pos_to_object_idx(pos)\n",
        "    return pos - numpy.round(pos)\n",
        "\n",
        "def get_view_at_pos(obj: numpy.ndarray, pos: ArrayLike) -> numpy.ndarray:\n",
        "    pos = numpy.array(pos)\n",
        "    if pos.ndim == 1:\n",
        "        return obj[slice_around_position(*pos)]\n",
        "\n",
        "    out = numpy.empty((*pos.shape[:-1], *ky.shape[-2:]), dtype=obj.dtype)\n",
        "    for idx in numpy.ndindex(pos.shape[:-1]):\n",
        "        out[*idx] = obj[slice_around_position(*pos[idx])]\n",
        "\n",
        "    return out\n",
        "\n",
        "def set_view_at_pos(obj: numpy.ndarray, pos: ArrayLike, view: numpy.ndarray):\n",
        "    pos = numpy.array(pos)\n",
        "    if pos.ndim == 1:\n",
        "        obj[slice_around_position(*pos)] = view\n",
        "        return\n",
        "\n",
        "    for idx in numpy.ndindex(pos.shape[:-1]):\n",
        "        obj[slice_around_position(*pos[idx])] = view[idx]\n",
        "\n",
        "def add_view_at_pos(obj: numpy.ndarray, pos: ArrayLike, view: numpy.ndarray):\n",
        "    pos = numpy.array(pos)\n",
        "    if pos.ndim == 1:\n",
        "        obj[slice_around_position(*pos)] += view\n",
        "        return\n",
        "\n",
        "    for idx in numpy.ndindex(pos.shape[:-1]):\n",
        "        obj[slice_around_position(*pos[idx])] += view[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "obj = numpy.zeros((n_y, n_x), dtype=numpy.float_)\n",
        "\n",
        "cutout = numpy.ones((128, 128), dtype=numpy.float_)\n",
        "\n",
        "pos = scan[[0, 20 + 64, 120, -1]]\n",
        "\n",
        "#set_view_at_pos(obj, pos, cutout)\n",
        "add_view_at_pos(obj, pos, cutout)\n",
        "\n",
        "fig, ax = pyplot.subplots()\n",
        "ax.invert_yaxis()\n",
        "ax.set_aspect(1.)\n",
        "fig.colorbar(ax.pcolormesh(xx, yy, obj))\n",
        "ax.scatter(pos[:, 0], pos[:, 1])\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSQ-ML method\n",
        "\n",
        "The LSQ-ML update step proceeds in three parts for each scan position $i$:\n",
        "\n",
        "1. Calculating the optimal exit wavefront $\\psi^{opt}_i$\n",
        "2. Calculating the object and probe update directions $\\Delta P_{i}$ and $\\Delta O_{i}$\n",
        "3. Calculating the object and probe optimal update steps $\\alpha_{P,i}$ and $\\alpha_{O,i}$\n",
        "\n",
        "The optimal exit wavefront $\\psi^{opt}_i$ is calculated to minimize the distance between expected/modeled intensity on the diffraction plane $I^e_{i}$ and the measured intensity $I^m_{i}$. Specifically, we choose the exit wavefront $\\psi^{opt}_i$ to maximize the likelihood $p(I^m_i|\\psi^{opt}_i)$. For this reference implementation, we replace this with a simple modulus constraint, which is the output of the ML optimization in the case where only Poisson noise is present in the amplitude likelihood model.\n",
        "\n",
        "To calculate real-space object and probe update, given an optimal exit wavefront, we calculate an 'exit wave update' $\\chi_{i,r}$ as the difference between our optimal and modeled exit wave:\n",
        "$$\n",
        "\\chi_{i,r} = \\psi^{opt}_{i,r} - \\psi^{fwd}_{i,r}\n",
        "$$\n",
        "\n",
        "We attempt to split $\\chi_{i,r}$ into probe and object updates, so as to minimize a real-space cost function $\\mathcal{L}_r$, defined as the sum squared error between the optimal exit wavefront and the updated wavefront:\n",
        "$$\\begin{aligned}\n",
        "\\mathcal{L}_r &= \\sum_{r} \\left| \\psi^{updated}_{i,r} - \\psi^{opt}_{i,r} \\right|^2\n",
        "\\end{aligned}$$\n",
        "\n",
        "Object and probe update directions are calculated as the gradient of the real-space cost function $\\mathcal{L}_r$:\n",
        "$$\\begin{aligned}\n",
        "\\Delta P_{i,r} &= -\\nabla_P \\mathcal{L}_r = \\chi_{i,r} O^*_{r+r_i} \\\\\n",
        "\\Delta O_{i,r+r_i} &= -\\nabla_O \\mathcal{L}_r = \\chi_{i,r} P^*_{r} \\\\\n",
        "\\end{aligned}$$\n",
        "\n",
        "(These gradients come from the complex derivative of $\\psi_{i, r} = P_{i, r} O_{i, r+r_i}$ assuming the second Wirtinger derivative $\\partial/\\partial \\tilde{z} = 0$)\n",
        "\n",
        "Over a batch $\\mathcal{N} \\subset \\mathcal{N}_0$, we average object and probe update directions:\n",
        "$$\\begin{aligned}\n",
        "\\Delta P_{r} &= \\frac{\\sum_{i \\in \\mathcal{N}} \\Delta P_{i,r}}{\\sum_{i \\in \\mathcal{N}_0} \\left| O_{r+r_i} \\right|^2 + \\delta_P} \\\\\n",
        "\\Delta O_{r+r_i} &= \\frac{\\sum_{i \\in \\mathcal{N}} \\Delta O_{r+r_i}}{\\sum_{i \\in \\mathcal{N}_0} \\left| P_{r} \\right|^2 + \\delta_O}\n",
        "\\end{aligned}$$\n",
        "\n",
        "\"$\\delta_O$ and $\\delta_P$ can be seen as preconditioners of the gradient descent task\", and \"penalize large values in the update, particularly in the weakly illuminated regions.\"\n",
        "The denominator sums can be considered the object and probe illumination, and are calculated for all positions to avoid noise amplification.\n",
        "\n",
        "Next, we calculate the step sizes $\\alpha_P$ and $\\alpha_O$. These can be calculated using the matrix (22), or assuming a diagonal matrix, in which case the step sizes become:\n",
        "$$\\begin{aligned}\n",
        "\\alpha_{P,i} = \\frac{\\sum_r Re\\left[ \\chi_{i,r} (\\Delta P_{i, r} O_{r+r_i} )^* \\right]}{\\sum_r \\left| \\Delta P_{i,r} O_{r+r_i} \\right|^2 + \\gamma} \\\\\n",
        "\\alpha_{O,i} = \\frac{\\sum_r Re\\left[ \\chi_{i,r} (\\Delta O_{i, r} P_{r} )^* \\right]}{\\sum_r \\left| \\Delta O_{i,r} P_r \\right|^2 + \\gamma}\n",
        "\\end{aligned}$$\n",
        "\n",
        "$\\gamma = 0.1$ in fold_slice?\n",
        "\n",
        "Finally, we update the probe and object as a weighted sum of updates:\n",
        "$$\\begin{aligned}\n",
        "P_r^{updated} &= P_r + \\frac{\\sum_{i \\in \\mathcal{N}} \\alpha_{P,i} \\Delta P_r \\left| O_{r+r_i} \\right|^2}{\\sum_{i \\in \\mathcal{N}} \\left| O_{r+r_i} \\right|^2} \\\\\n",
        "O_r^{updated} &= O_r + \\frac{\\sum_{i \\in \\mathcal{N}} \\alpha_{P,i} \\Delta P_r \\left| P_{r-r_i} \\right|^2}{\\sum_{i \\in \\mathcal{N}} \\left| P_{r-r_i} \\right|^2}\n",
        "\\end{aligned}$$\n",
        "\n",
        "Note that step sizes are calculated per scan position (and then averaged as a function of illumination), but step directions are averaged together into a single step direction per grouping. In practice, we need to add a small epsilon in the denominator to prevent 0/0 conditions."
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Iteration loop"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# experimental data, shape (N, ky, kx)\n",
        "exp_data = raw\n",
        "\n",
        "# random start object\n",
        "rng = numpy.random.RandomState(seed=123456)\n",
        "obj_angle = rng.normal(0., 1e-8, (n_y, n_x))\n",
        "obj = (numpy.cos(obj_angle) + numpy.sin(obj_angle) * 1.j)\n",
        "\n",
        "# probe model\n",
        "probes = init_probes[:1].copy() / 0.94\n",
        "#probes = init_probes.copy()\n",
        "\n",
        "# delta_P and delta-O in eq. 25\n",
        "illum_reg_P = 1e-3 # * numpy.prod(probe.shape[-2:])\n",
        "illum_reg_O = 1e-3 # * numpy.prod(probe.shape[-2:])\n",
        "# gamma in eq. 23, 0.1 in fold_slice\n",
        "gamma = 0.1 * numpy.prod(probes.shape[-2:])\n",
        "# small epsilon to prevent 0/0\n",
        "eps = 1e-16\n",
        "\n",
        "obj_mag = numpy.zeros(probes.shape[-2:], dtype=numpy.float64)\n",
        "probe_mag = numpy.zeros_like(obj, dtype=numpy.float64)\n",
        "\n",
        "# pre-calculate obj_mag and probe_mag\n",
        "\n",
        "# this loop should also fix incident probe intensity\n",
        "groups = calc_groupings(16, 1234567)\n",
        "for (group_i, group) in enumerate(groups):\n",
        "    group_scan = scan[group]\n",
        "    # group probes in real space\n",
        "    # shape (len(group), 1, Ny, Nx)\n",
        "    group_subpx_filters = fourier_shift_filter(ky, kx, get_subpx_shifts(group_scan))[:, None, ...]\n",
        "    # shape (len(group), probe modes, Ny, Nx)\n",
        "    group_probes = ifft2(fft2(probes) * group_subpx_filters)\n",
        "    add_view_at_pos(probe_mag, group_scan, numpy.sum(abs2(group_probes), axis=1) / numpy.sqrt(numpy.prod(probes.shape[-2:])))\n",
        "    obj_mag += numpy.sum(get_view_at_pos(abs2(obj), group_scan), axis=0) / numpy.sqrt(numpy.prod(probes.shape[-2:]))\n",
        "\n",
        "for i in range(5):\n",
        "    groups = calc_groupings(8, 1234567 + i)\n",
        "\n",
        "    new_obj_mag = numpy.zeros(probes.shape[-2:], dtype=numpy.float64)\n",
        "    new_probe_mag = numpy.zeros_like(obj, dtype=numpy.float64)\n",
        "\n",
        "    for (group_i, group) in enumerate(groups):\n",
        "        group_scan = scan[group]\n",
        "        # group probes in real space\n",
        "        # shape (len(group), 1, Ny, Nx)\n",
        "        group_subpx_filters = fourier_shift_filter(ky, kx, get_subpx_shifts(group_scan))[:, None, ...]\n",
        "        # shape (len(group), probe modes, Ny, Nx)\n",
        "        group_probes = ifft2(fft2(probes) * group_subpx_filters)\n",
        "        # add to illumination\n",
        "        group_probe_mag = numpy.zeros_like(obj, dtype=numpy.float64)\n",
        "        add_view_at_pos(group_probe_mag, group_scan, numpy.sum(abs2(group_probes), axis=1) / numpy.sqrt(numpy.prod(probes.shape[-2:])))\n",
        "        new_probe_mag += group_probe_mag\n",
        "\n",
        "        # experimental data\n",
        "        group_patterns = exp_data[group]\n",
        "\n",
        "        # shape (len(group), 1, Ny, Nx)\n",
        "        group_objs = get_view_at_pos(obj, group_scan)[:, None, ...]\n",
        "        # add to illumination\n",
        "        group_obj_mag = numpy.sum(abs2(group_objs), axis=0) / numpy.sqrt(numpy.prod(probes.shape[-2:]))\n",
        "        new_obj_mag += group_obj_mag[0]\n",
        "\n",
        "        exit_wave = group_objs * group_probes\n",
        "\n",
        "        pattern_model = fft2(exit_wave)\n",
        "        # sum over incoherent modes\n",
        "        intensity_model = numpy.sum(abs2(pattern_model), axis=1)\n",
        "\n",
        "        # modulus constraint\n",
        "        intensity_update = numpy.sqrt(group_patterns / (intensity_model + 1e-18)) - 1.0\n",
        "        chi = ifft2(pattern_model * intensity_update[:, None, ...])\n",
        "\n",
        "        # eq. 24, update directions per probe position\n",
        "        delta_P = chi * numpy.conj(group_objs) # and probe mode\n",
        "        delta_O = chi * numpy.conj(group_probes)\n",
        "\n",
        "        # eq. 23, calculate step size per probe position and mode\n",
        "        # we take the diagonal approxmiation\n",
        "        alpha_P = numpy.sum(numpy.real(chi * numpy.conj(delta_P * group_objs)), axis=(-1, -2), keepdims=True) / (numpy.sum(abs2(delta_P * group_objs)) + gamma)\n",
        "        # sum over probe modes as well\n",
        "        alpha_O = numpy.sum(numpy.sum(numpy.real(chi * numpy.conj(delta_O * group_probes)), axis=(-1, -2), keepdims=True), axis=1) / (numpy.sum(abs2(delta_O * group_probes)) + gamma)\n",
        "        #print(f\"alpha_P: {list(alpha_P.ravel())}\")\n",
        "        #print(f\"alpha_O: {list(alpha_O.ravel())}\")\n",
        "\n",
        "        # eq. 25, average update directions\n",
        "        # apply subpx shifts in reciprocal space\n",
        "        # delta_P_avg is in cutout space\n",
        "        delta_P_avg = ifft2(numpy.sum(fft2(delta_P) / group_subpx_filters, axis=0))\n",
        "        delta_P_avg /= (obj_mag + illum_reg_P)\n",
        "        # delta_O_avg is in object space\n",
        "        delta_O_avg = numpy.zeros_like(obj)\n",
        "        # sum over probe modes as well\n",
        "        add_view_at_pos(delta_O_avg, group_scan, numpy.sum(delta_O, axis=1))\n",
        "        delta_O_avg /= (probe_mag + illum_reg_O)\n",
        "\n",
        "        # eq. 27, final probe and object update\n",
        "        # note that probe update is performed in cutout space, while object update is performed in full object space\n",
        "        # a small epsilon is added to prevent 0/0 -> nan\n",
        "        probe_update = numpy.sum(alpha_P * delta_P_avg * group_obj_mag, axis=0) / (group_obj_mag + eps)\n",
        "        obj_update = numpy.sum(alpha_O * delta_O_avg * group_probe_mag, axis=0) / (group_probe_mag + eps)\n",
        "\n",
        "        probes += probe_update\n",
        "        obj += obj_update\n",
        "\n",
        "    break\n",
        "    # update current obj_mag and probe_mag\n",
        "    obj_mag = new_obj_mag\n",
        "    probe_mag = new_probe_mag\n",
        "\n",
        "    print(f\"Finished iter #{i+1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = pyplot.subplots(ncols=2, nrows=3)\n",
        "fig.set_size_inches(4, 7)\n",
        "\n",
        "for ax in axs.ravel():\n",
        "    ax.set_axis_off()\n",
        "\n",
        "axs[0, 1].sharex(axs[0, 0])\n",
        "axs[0, 1].sharey(axs[0, 0])\n",
        "for idxs in ((1, 1), (2, 0), (2, 1)):\n",
        "    axs[*idxs].sharex(axs[1, 0])\n",
        "    axs[*idxs].sharey(axs[1, 0])\n",
        "\n",
        "pattern_max = max(map(numpy.nanmax, (group_patterns[0], intensity_model[0])))\n",
        "\n",
        "axs[0, 0].set_title(\"Object\")\n",
        "if True:\n",
        "    crop = numpy.ceil(sim_r / numpy.array([px_size_y, px_size_x])).astype(numpy.int_)\n",
        "    crop = (slice(crop[0], -crop[0]), slice(crop[0], -crop[0]))\n",
        "else:\n",
        "    crop = (slice(0, None), slice(0, None))\n",
        "\n",
        "axs[0, 0].imshow(remove_phase_ramp(numpy.angle(obj[*crop])))\n",
        "\n",
        "#axs[0].imshow(numpy.angle(obj))\n",
        "axs[1, 0].set_title(\"Measured Pattern\")\n",
        "axs[1, 0].imshow(numpy.fft.fftshift(group_patterns[0]), vmin=0., vmax=pattern_max)\n",
        "axs[1, 1].set_title(\"Recons. Pattern\")\n",
        "axs[1, 1].imshow(numpy.fft.fftshift(intensity_model[0]), vmin=0., vmax=pattern_max)\n",
        "axs[0, 1].set_title(\"Obj update phase\")\n",
        "axs[0, 1].imshow(numpy.angle(obj_update[*crop]))\n",
        "axs[2, 0].set_title(\"Probe\")\n",
        "axs[2, 0].imshow(numpy.sum(abs2(probes), axis=0))\n",
        "axs[2, 1].set_title(\"Probe update phase\")\n",
        "axs[2, 1].imshow(numpy.angle(probe_update[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = pyplot.subplots(ncols=probes.shape[0], sharex=True, sharey=True, squeeze=False)\n",
        "\n",
        "for (ax, probe) in zip (axs.flat, probes):\n",
        "    ax.set_axis_off()\n",
        "    ax.set_title(\"{:.3f}\".format(numpy.sum(abs2(probe)) / numpy.prod(probe.shape[-2:])))\n",
        "    #ax.imshow(abs2(numpy.fft.fftshift(fft2(probe))))\n",
        "    ax.imshow(abs2(probe))\n",
        "\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "pyplot.close('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = pyplot.subplots(ncols=3, sharex=True, sharey=True)\n",
        "\n",
        "axs[0].imshow(numpy.fft.fftshift(raw[0]))\n",
        "axs[1].imshow(numpy.fft.fftshift(raw[1]))\n",
        "axs[2].imshow(numpy.fft.fftshift(raw[2]))\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot probe modes\n",
        "\n",
        "fig, axs = pyplot.subplots(ncols=len(delta_O), sharex=True, sharey=True, squeeze=False)\n",
        "\n",
        "for (ax, upd) in zip (axs.flat, delta_O):\n",
        "    ax.set_axis_off()\n",
        "    #ax.imshow(abs2(numpy.fft.fftshift(fft2(probe))))\n",
        "    ax.imshow(abs2(upd[0]))\n",
        "\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = pyplot.subplots()\n",
        "\n",
        "ax.imshow(numpy.fft.fftshift(group_patterns[0]))\n",
        "pyplot.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
